# ContextForge Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Configuration
# =============================================================================
# ContextForge supports multiple LLM providers. Configure at least one:
# - Ollama (local, recommended for privacy)
# - OpenAI (remote, requires API key)
# - Anthropic Claude (remote, requires API key)
# - LM Studio (local alternative to Ollama)

# OpenAI API
OPENAI_API_KEY=

# Anthropic Claude API
ANTHROPIC_API_KEY=

# Mistral AI API
MISTRAL_API_KEY=

# =============================================================================
# Web Search API Keys
# =============================================================================

# SerpAPI (Google Search)
SERPAPI_KEY=

# Bing Web Search API
BING_SUBSCRIPTION_KEY=

# Google Custom Search Engine
GOOGLE_CSE_KEY=
GOOGLE_CSE_ID=

# =============================================================================
# Local LLM Endpoints
# =============================================================================

# Ollama (local)
OLLAMA_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=mistral

# LM Studio (local)
LM_STUDIO_URL=http://localhost:8085/generate

# =============================================================================
# Service Configuration
# =============================================================================

# Internal service URLs (for Docker Compose)
VECTOR_INDEX_URL=http://vector-index:8001
PREPROCESSOR_URL=http://preprocessor:8003
CONNECTOR_URL=http://connector:8002
WEB_FETCHER_URL=http://web-fetcher:8004

# LLM Priority (comma-separated, first available wins)
# Options: ollama, lm_studio, openai, anthropic
# Default: ollama (requires Ollama to be running)
LLM_PRIORITY=ollama

# Web search configuration
ENABLE_WEB_SEARCH=True
WEB_SEARCH_RESULTS=5

# =============================================================================
# Runtime Configuration
# =============================================================================

# Logging level
LOG_LEVEL=INFO

# Request timeouts (seconds)
LLM_TIMEOUT=30
SEARCH_TIMEOUT=10
EMBEDDING_TIMEOUT=15

# Vector search parameters
VECTOR_TOP_K=10
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# =============================================================================
# Data Privacy Settings
# =============================================================================

# Set to 'local' to prevent any remote LLM calls
# Set to 'hybrid' to allow remote calls with user consent
# Set to 'remote' to allow all remote calls
PRIVACY_MODE=local
